import torch
import torch.nn.functional as F
from typing import Dict, Tuple, List

from utils.metrics import compute_metrics


@torch.no_grad()
def evaluate(model, loader, device) -> Tuple[float, Dict[str, float]]:
    model.eval()
    total_loss = 0.0
    total_n = 0

    ys: List[int] = []
    preds: List[int] = []

    for data in loader:
        data = data.to(device)
        logits = model(data)
        y = data.y.view(-1).long()

        loss = F.cross_entropy(logits, y)
        total_loss += loss.item() * y.size(0)
        total_n += y.size(0)

        probs = torch.softmax(logits, dim=1)[:, 1]  # å–å‡ºå±žäºŽ Webshell ç±»åˆ«çš„æ¦‚çŽ‡
        threshold = 0.3  # ðŸ”¥ å…³é”®ï¼šé™ä½Žé˜ˆå€¼ï¼ä»Ž 0.5 é™åˆ° 0.3 ç”šè‡³ 0.2
        pred = (probs > threshold).long().detach().cpu().tolist()
        ys.extend(y.detach().cpu().tolist())
        preds.extend(pred)

    avg_loss = total_loss / max(1, total_n)
    metrics = compute_metrics(ys, preds)
    return avg_loss, metrics
